---
title: "Nurse Models"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: cosmo
    highlight: kate
    df_print: paged
    code_folding: hide
date: "2024-08-19"
---

```{r setup, include = FALSE}
library(knitr)

# Set up knitr options
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  autodep = TRUE,
  cache = FALSE,
  cache.comments = FALSE
)
options(np.messages = FALSE)

```

```{r load code and data, include = FALSE}
# Source helper functions
source(file.path("code", "utils", "load_packages.R"))

packages <- c(
  "broom",  
  "car",
  "DiagrammeR",
  "dplyr",
  "emmeans",
  "forcats",
  "ggplot2",
  "ggtext",
  "gt", 
  "haven",
  "kableExtra",
  "lavaan",
  "mediation", 
  "patchwork", 
  "purrr", 
  "showtext", 
  "stringr", 
  "tibble", 
  "tidyr"
)

load_packages(packages)

source(file.path("code", "utils", "grab_columns.R"))
source(file.path("code", "utils", "07_logistic_model_helpers.R"))
source(file.path("code", "utils", "07_load_logistic_data.R"))
source(file.path("code", "utils", "07b_utils.R"))
source(file.path("code", "utils", "05_distribution_plots.R"))
source(file.path("code", "preliminary analyses", "05_eda.R"))
```

Note: Magnet status is collapsed in the following analyses, such that "I don't know" values will be treated similarly to "No"s.

```{r}

df_nurses <- df_nurses %>%
  mutate(
    magnet_collapsed = case_when(
      magnet == "Yes" ~ "Yes",
      magnet %in% c("No", "I don't know") ~ "No",
      TRUE ~ NA_character_
    )) %>%
  rowwise() %>%
  mutate(
    leadership_use= mean(c(as.numeric(a1_8), as.numeric(a1_9)), na.rm = TRUE),
    leadership_reliability = mean(c(as.numeric(b1_8), as.numeric(b1_9)), na.rm = TRUE)
  ) %>%
  filter(!is.na(magnet_collapsed))

```

# Information Source Use

## Distribution Plots

```{r, echo = FALSE, fig.height = 13, fig.width = 8, message = FALSE}
a_vars <- get_column_names(survey_results, "a1_1", "a1_15")
b_vars <- get_column_names(survey_results, "b1_1", "b1_15")

info_source_items <- list(a_vars, b_vars)

magnet_info_use <- lapply(info_source_items, function(vars) {
  overview_subsets(
    df_nurses,
    vars,
    subset_var = "magnet_collapsed",
    plot_by = "color",
    chosen_palette = "p2",
    leg_label = "Magnet Status",
    xjust = .9
  )
})

magnet_info_use[[1]]

```

We see no indications of significant differences in use of information sources as a function of Magnet status.


## Summary Boxplots

```{r boxplots, width = 8, height = 4}
# Draw boxplots for time differences using the long-format table
df_long_time <- df_nurses %>%
  pivot_longer(
    cols = matches("^subscale[1-4]_avg_(a|b)$"),
    names_to = "variable",
    values_to = "value"
  ) %>%
  mutate(
    time = case_when(
      grepl("_a$", variable) ~ "pandemic",
      grepl("_b$", variable) ~ "reliability"
    ),
    item = str_extract(variable, "^subscale[1-4]_avg")
  ) %>%
  filter(
    time %in% c("pandemic", "reliability")) %>%
  dplyr::select(magnet_collapsed, variable, value, time, item) %>%
  mutate(
    item = dplyr::recode(item,
                         "subscale1_avg" = "Professional Networks and Authorities",
                         "subscale2_avg" = "News and Social Media",
                         "subscale3_avg" = "Academic Publications",
                         "subscale4_avg" = "Blogs and Podcasts"
    ))

ggplot(df_long_time, aes(x = time, y = value, fill = magnet_collapsed)) +
  geom_boxplot() +
  facet_wrap(~ item, scales = "free_y") +
  labs(title = "Information Use Subscales by Magnet Status",
       x = "Time Period",
       y = "Average Value",
       fill = "Magnet Status") +
  theme_minimal() +
  theme(
    plot.title      = element_text(size = 25, face = "bold"),
    axis.title.x    = element_text(size = 22),
    axis.title.y    = element_text(size = 22),
    axis.text.x     = element_text(size = 20),
    axis.text.y     = element_text(size = 20),
    strip.text      = element_text(size = 20),  # facet labels
    legend.title    = element_text(size = 22),
    legend.text     = element_text(size = 20)
  ) +
  scale_fill_manual(
    values = c(
      "No" = "#1b9e77",
      "Yes"  = "#d95f02"
    )
  )

```

# Organizational Attitudes

## Distribution Plots

```{r, echo = FALSE, fig.height = 9, fig.width = 8, message = FALSE}
org_attitude_questions <- c(paste0("b4_", 1:4), paste0("c4_", 1:4))

## Overview plots by magnet status
org_attitudes_by_magnet <- overview_subsets(
  df = df_nurses,
  question_numbers = org_attitude_questions,
  subset_var = "magnet_collapsed",
  plot_by = "color",
  chosen_palette = "p2",
  leg_label = "Magnet Status",
  xjust = .9
)
org_attitudes_by_magnet

```

# Adoption Patterns

```{r include = FALSE}
# Plot # of clinicians adopting innovations
source(file.path("code", "utils", "05_adoption_table.R"))
```

Here were the patterns of innovation adoption among the sample of 757 nurses:

```{r include = FALSE}
# Ensure Magnet is a factor
df_nurses <- df_nurses %>%
  mutate(magnet_collapsed = factor(magnet_collapsed, levels = c("Yes","No")))

# --- Summarise magnet groups correctly ---
summarize_subset_magnet <- function(df, suggest_col, flex_col = NULL,
                                   subset_label = "All nurses", filter_flex = FALSE) {

  data_sub <- df
  if (filter_flex && !is.null(flex_col)) {
    data_sub <- data_sub %>%
      dplyr::filter(.data[[flex_col]] %in% c(2, 3))
  }

  # Calculate by Magnet
  by_magnet <- data_sub %>%
    dplyr::group_by(magnet_collapsed) %>%
    dplyr::summarise(
      denom = sum(!is.na(.data[[suggest_col]])),
      n     = sum(.data[[suggest_col]] == 1, na.rm = TRUE),
      pct   = ifelse(denom > 0, 100 * n / denom, NA_real_),
      .groups = "drop"
    )

  # Calculate overall total (no grouping)
  total <- data_sub %>%
    dplyr::summarise(
      denom = sum(!is.na(.data[[suggest_col]])),
      n     = sum(.data[[suggest_col]] == 1, na.rm = TRUE),
      pct   = ifelse(denom > 0, 100 * n / denom, NA_real_)
    ) %>%
    dplyr::mutate(magnet_collapsed = "Total")

  dplyr::bind_rows(by_magnet, total) %>%
    dplyr::mutate(subset = subset_label)
}

# --- Build the tidy summaries ---
adoption_long_magnet <-
  innovation_map %>%
  dplyr::mutate(res = purrr::pmap(., function(innovation, suggest_col, flex_col, pretty) {

    all_tbl <- summarize_subset_magnet(
      df_nurses, suggest_col = suggest_col,
      subset_label = "All nurses", filter_flex = FALSE)

    flex_tbl <- summarize_subset_magnet(
      df_nurses, suggest_col = suggest_col,
      flex_col = flex_col,
      subset_label = "Flexible for this innovation", filter_flex = TRUE)

    dplyr::bind_rows(all_tbl, flex_tbl) %>%
      dplyr::mutate(innovation = pretty)
  })) %>%
  dplyr::pull(res) %>%
  dplyr::bind_rows()

# --- Format for output ---
adoption_table_pretty_magnet <- adoption_long_magnet %>%
  dplyr::select(-denom) %>%
  dplyr::mutate(
    magnet_collapsed = factor(magnet_collapsed, levels = c("Yes", "No", "Total")),
    subset = factor(subset, levels = c("All nurses","Flexible for this innovation")),
    pct  = round(pct, 1),
    cell = dplyr::if_else(is.na(n) | is.na(pct),
                          NA_character_,
                          sprintf("%d (%.1f%%)", n, pct))
  ) %>%
  dplyr::group_by(innovation, subset, magnet_collapsed) %>%
  dplyr::summarise(cell = first(cell), .groups = "drop") %>%
  tidyr::pivot_wider(names_from = magnet_collapsed, values_from = cell)

# --- Compute totals again, grouped by innovation + subset ---
adoption_table_pretty_magnet <- adoption_table_pretty_magnet %>%
  dplyr::rowwise() %>%
  dplyr::mutate(Total = {
    # extract counts & percentages from Yes / No columns to recompute correctly
    nums <- stringr::str_extract_all(c(Yes, No), "^[0-9]+") %>% unlist() %>% as.numeric()
    pcts <- stringr::str_extract_all(c(Yes, No), "(?<=\\()[0-9\\.]+") %>% unlist() %>% as.numeric()
    if (length(nums) == 2 && all(!is.na(nums))) {
      total_n <- sum(nums)
      total_pct <- mean(pcts, na.rm = TRUE)
      sprintf("%d (%.1f%%)", total_n, total_pct)
    } else NA_character_
  }) %>%
  dplyr::ungroup()

# --- Display ---
knitr::kable(adoption_table_pretty_magnet, format = "html",
             caption = "Adoption Summary – Nurses by Magnet Status") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "responsive"),
                            position = "center") %>%
  kableExtra::kable_minimal()

```

```{r}
adoption_table_pretty_magnet %>%
  gt() %>%
  tab_header(
    title = "Innovation Adoption Among Nurses by Magnet Status",
    subtitle = "Number and percentage of adopters"
  ) %>%
  cols_label(
    innovation = "Innovation",
    subset     = "Sample",
    Yes        = "Magnet Hospitals",
    No         = "Non‑Magnet Hospitals",
    Total      = "All Nurses"
  ) %>%
  tab_spanner(
    label = "Magnet Status",
    columns = c(Yes, No)
  ) %>%
  opt_row_striping() %>%
  tab_options(
    table.font.size = px(12)
  )
```


# H1: Information Source Use

## H1A: RNs in Magnet hospitals were more likely to report getting information from leadership during the pandemic

The model below tests whether nurses in Magnet hospitals, compared to those at non-Magnet hospitals, relied more on ED leadership (e.g., Department Chair, Nurse Manager) and hospital/organization leadership (e.g., Chief Medical Officer, Chief Nursing Officer) to access information about COVID-19 care innovations in the early pandemic. Items were rated on a 1-5 scale, from "never" to "frequently". Here, the outcome variable represents the average of these two items. 

We also control for age, gender, and perceptions of the leadership sources' reliability. Here, the variability "scale(age)" indicates a one-SD change, rather than a one-year change, to aid interpretation.

```{r}
h1_predictors <- c("magnet_collapsed", "scale(age)", "gender_collapsed", "leadership_reliability")

## Nurses
h1_result <- run_linear_regression(
  data = df_nurses,
  predictors = h1_predictors, 
  response = "leadership_use"
)

```
```{r include = FALSE}
# Confirm no serious multicollinearity
car::vif(h1_result)
```

Magnet status does not predict greater use of hospital leadership as an information source. However, perceptions of leadership reliability do.

```{r}
summary(lm(leadership_reliability ~ magnet_collapsed, data = df_nurses))
```

Nurses at magnet hospitals did not rate their leadership as more reliable than nurses at non-magnet hospitals (p > .05).

However, leaders' perceived reliability strongly predicted reliance on leadership information.

```{r}
ggplot(df_nurses, aes(leadership_reliability, leadership_use, color = magnet_collapsed)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Perceived Leadership Reliability",
       y = "Reliance on Leadership for COVID-19 Information",
       color = "Magnet Status") +
  theme_minimal() +
  theme(
    text = element_text(size = 20),          # sets base for all text
    axis.title = element_text(size = 22),    # axis titles
    axis.text  = element_text(size = 18),    # tick labels
    legend.title = element_text(size = 20),
    legend.text  = element_text(size = 18)
  ) +
  scale_fill_manual(
    values = c(
      "No" = "#1b9e77",
      "Yes"  = "#d95f02"
    )
  )
```

## Exploratory H1B: Do perceptions of organizational practices predict perceptions of leadership reliability?

ED innovation and organizational leadership scores independently predicted perceptions of leadership reliability, though these constructs are moderately correlated, as denoted by the correlation table at the bottom.

```{r}
h1b_predictors <- c(
  "ed_transpar_avg", "ed_innov_avg", "org_collab_avg", "org_lead_avg",
  "scale(age)", "gender_collapsed"
)

## Nurses
h1b_result <- run_linear_regression(
  data = df_nurses,
  predictors = h1b_predictors, 
  response = "leadership_reliability"
)

# Multicollinearity doesn't appear to be an issue
cor(df_nurses %>% dplyr::select(ed_transpar_avg, ed_innov_avg, org_collab_avg, org_lead_avg), use = "pairwise")
```

In the following exploratory analysis, I test whether items assessing perceptions of organizational leadership shape perceptions of leadership's reliability as a source of information. These are the specific items tested:

1: My organization’s leadership has a strong vision that supports high standards for clinical practice. 
2. My organization’s leadership can be counted on to support the clinical care team. 

Perceptions of a strong organizational vision and supportive leadership were positively associated with nurses’ perceptions of leadership reliability.

In turn, perceived reliability predicted nurses’ reliance on leadership sources for information during the early pandemic.

Model fit was acceptable (CFI=.96, RMSEA=.10). The standardized paths (β=.12–.53) suggested meaningful relationships consistent with the hypothesis that leadership practices shape perceptions of leadership, which drive utilization by nurses.

```{r}
df_nurses <- df_nurses %>%
  mutate(
    vision          = as.numeric(as.character(c4_1)),
    support         = as.numeric(as.character(c4_2)))

# Define lavaan model as a text string
model <- '
  # direct paths
  leadership_reliability  ~ vision + support
  leadership_use ~ leadership_reliability
'

# Fit the SEM
fit <- sem(model, data = df_nurses)

# Summarize results
summary(fit, standardized = TRUE, fit.measures = TRUE)
```


Finally, I confirmed that Magnet status does not contribute to any noticeable changes in fit metrics (CFI, RMSEA, etc.)
Magnet designation adds no explanatory value beyond perceived leadership practices.

```{r}
robust_model <- '
  leadership_reliability ~ vision + support + magnet_collapsed
  leadership_use ~ leadership_reliability
'
robust_fit <- sem(robust_model, data = df_nurses)
summary(robust_fit, standardized = TRUE, fit.measures = TRUE)
```
Here is a visualization of the path model:

```{r}
grViz("
  digraph leadershipModel {
    graph [layout = dot, rankdir = LR]
    node [shape = rectangle, style = filled, fillcolor = lightgrey]
      Vision Support Magnet
      Reliability [label = 'Perceived Leadership Reliability']
      Use [label = 'Leadership Use']
    Vision -> Reliability [label = 'β = .12']
    Support -> Reliability [label = 'β = .22']
    Magnet -> Reliability [label = 'ns']
    Reliability -> Use [label = 'β = .53']
  }
")
```


# H2: Implementation

## Statistical Considerations 

Before answering this question, it's important to understand that only 48 nurses reused N95s, had some or total flexibility to do so, and were in magnet hospitals. 88 reused N95s, had flexibility, and weren't in magnet hospitals. That means that we're testing differences among a fairly small group and may be underpowered to detect effects.

```{r}
df_nurses %>%
  group_by(magnet_collapsed, ppe1a, ppe1b) %>%
  summarize(n = n(), .groups = "drop") %>%
  dplyr::rename(
    "Magnet Status" = magnet_collapsed,
    "Decision to Reuse PPE" = ppe1a,
    "Flexibility to Make Decision" = ppe1b,
    "Count" = n
  ) %>%
  knitr::kable(format = "html", caption = "Counts by Magnet Status and PPE Variables") %>%
  kableExtra::kable_styling(full_width = FALSE, position = "center")

```

## H2A: Among RNs who reused N95s and had either some or total flexibility to do so, the RNs in Magnet hospitals were less likely to use colleagues or anecdotes to shape their decision-making compared to those in non-Magnet hospitals.

```{r}

h2_predictors <- c("magnet_collapsed", "age", "gender_collapsed", "ppe1b")
cat("What colleagues at my institution were doing: ")

h2a_result <- run_filtered_logistic(
  data = df_nurses,
  filters = list(
    ppe1a = c(1),
    ppe1b = c(2, 3)
  ),
  predictors = h2_predictors,
  response = "ppe1c_3"
)
```

Nurses at Magnet hospitals (vs. those at non-Magnet hospitals) *were* more likely to use colleagues' feedback to make decisions about PPE reuse. This effect, notably, is stronger when *not* only considering nurses who reused PPE.

## H2B

```{r}
cat("What colleagues at other institutions were doing: ")

h2b_result <- run_filtered_logistic(
  data = df_nurses,
  filters = list(
    ppe1a = c(1),
    ppe1b = c(2, 3)
  ),
  predictors = h2_predictors,
  response = "ppe1c_4"
)

```

## H2C

```{r}
cat("Stories/anecdotes about patient outcomes: ")

h2c_result <- run_filtered_logistic(
  data = df_nurses,
  filters = list(
    ppe1a = c(1),
    ppe1b = c(2, 3)
  ),
  predictors = h2_predictors,
  response = "ppe1c_9"
)

```

## Corrected Estimates

Here are the H2 estimates corrected for multiple comparisons:

```{r}
H2_models  <- list(h2a_result, h2b_result, h2c_result)
H2_labels  <- c("H2A", "H2B", "H2C")

H2_pvals <- adjust_family(H2_models, H2_labels)

H2_pvals %>%
  dplyr::select(model, term, estimate, p.value, pval_adj_holm, sig) %>%
  dplyr::mutate(across(where(is.numeric), ~ round(.x, 3))) %>%
  knitr::kable(format = "html", caption = "Condensed H2 Model Estimates") %>%
  kableExtra::kable_styling(full_width = FALSE)
```

Although we found that Magnet status predicted being more likely to cite colleagues at one's own institution in the decision to reuse PPE, this effect does not survive correct for multiple comparisons (i.e., adjusting for the 3 tests that we ran in hypothesis 2.)


# H3: Deimplementation

## Statistical Considerations

Before answering this question, it's important to note that we have yet to analyze *which* innovations were discontinued, so the following results may be difficult to interpret.

Secondly, it's again important to understand how often anecdotal results were cited as a factor in the decision to discontinue an innovation:

```{r}
# Within your ED
df_nurses %>%
  group_by(magnet_collapsed) %>%
  count(b3_2) %>%
  rename(
    "Magnet Status" = magnet_collapsed,
    "Outcome Response" = b3_2,
    "Count" = n
  ) %>%
  kable(format = "html",
        caption = "Anecdotal results/outcomes from within your ED") %>%
  kable_styling(full_width = FALSE, position = "center")

# Colleagues elsewhere
df_nurses %>%
  group_by(magnet_collapsed) %>%
  count(b3_3) %>%
  rename(
    "Magnet Status" = magnet_collapsed,
    "Outcome Response" = b3_3,
    "Count" = n
  ) %>%
  kable(format = "html",
        caption = "Anecdotal results/outcomes from colleagues elsewhere") %>%
  kable_styling(full_width = FALSE, position = "center")

# Online/social media sources
df_nurses %>%
  group_by(magnet_collapsed) %>%
  count(b3_4) %>%
  rename(
    "Magnet Status" = magnet_collapsed,
    "Outcome Response" = b3_4,
    "Count" = n
  ) %>%
  kable(format = "html",
        caption = "Anecdotal results/outcomes from online and social media sources") %>%
  kable_styling(full_width = FALSE, position = "center")
```

I will collapse the three items about using anecdotal outcomes to guide de-implementation because there is not a theoretical justification that I am aware of for distinguishing them.

## H3A: RNs in Magnet hospitals were less likely to report that ED COVID-19 care innovations were discontinued due to anecdotal results compared to those in non-Magnet hospitals.

In the following analysis, age is a positive, statistically significant predictor of considering anecdotes when making decisions about de-implementation, but the effect is tiny and not seemingly meaningful. Magnet status is not associated with considering anecdotes.

```{r}
df_nurses <- df_nurses %>%
  mutate(
    across(c(b3_2, b3_3, b3_4), ~ as.numeric(as.character(.x))),  # convert factors to numeric
    anecdotal_used_any = if_else(
      rowSums(pick(b3_2, b3_3, b3_4), na.rm = TRUE) > 0, 1, 0
    )
  )

h3_predictors <- c("magnet_collapsed", "age", "gender_collapsed")

h3_combined_result  <- run_logistic_regression(
  data = df_nurses,  
  predictors = h3_predictors,
  response = "anecdotal_used_any"
)
```

Only age is significantly (negatively) predictive of considering anecdotal results from within one's ED when making decisions about de-implementation.